{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "746af758-f239-4271-9f8b-00e4f32beaf4",
   "metadata": {},
   "source": [
    "# Transformer: BERT Style Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f642d38-d35c-473b-b858-124ed910cf8e",
   "metadata": {},
   "source": [
    "## Functional API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75ca968-a930-44af-9ec4-56d89486a99c",
   "metadata": {},
   "source": [
    "### Input Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aedee0a8-f9cc-4ce0-8b69-801826584613",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def wpe(length: int, depth: int) -> tf.Tensor:\n",
    "    \"\"\"Word Positional Encoding.\n",
    "\n",
    "    This function is used to encode the position of each token in the sequence,\n",
    "    which is then added to the embedding of each token.\n",
    "\n",
    "    Args:\n",
    "        length: Sequence length.\n",
    "        depth: Embedding depth.\n",
    "\n",
    "    Returns:\n",
    "        Positional encoding tensor of shape (length, depth).\n",
    "    \"\"\"\n",
    "    depth = depth / 2\n",
    "\n",
    "    # (seq, 1)\n",
    "    positions = tf.range(length, dtype=tf.float32)[:, tf.newaxis]\n",
    "    # (1, depth)\n",
    "    depths = tf.range(depth, dtype=tf.float32)[tf.newaxis, :] / depth\n",
    "\n",
    "    angle_rates = 1 / (10000**depths)  # (1, depth)\n",
    "    angle_rads = positions * angle_rates  # (pos, depth)\n",
    "\n",
    "    return tf.concat([tf.sin(angle_rads), tf.cos(angle_rads)], axis=-1)\n",
    "\n",
    "\n",
    "def wte(x: tf.Tensor, vocab_size: int, depth: int) -> tf.Tensor:\n",
    "    \"\"\"Word Token Embedding.\n",
    "\n",
    "    This function is used to encode each token in the sequence into a vector.\n",
    "\n",
    "    Args:\n",
    "        x: Token ID sequence tensor of shape (batch, seq).\n",
    "        vocab_size: Vocabulary size.\n",
    "        depth: Embedding depth.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: Embedding tensor of shape (batch, seq, depth).\n",
    "    \"\"\"\n",
    "    return tf.keras.layers.Embedding(vocab_size, depth)(x)\n",
    "\n",
    "\n",
    "def embedding(x: tf.Tensor, vocab_size: int, depth: int) -> tf.Tensor:\n",
    "    \"\"\"Input Embedding.\n",
    "\n",
    "    This function is used to encode each token in the sequence into a vector,\n",
    "    and then add the positional encoding to each token.\n",
    "\n",
    "    Args:\n",
    "        x: Token ID sequence tensor of shape (batch, seq).\n",
    "        vocab_size: Vocabulary size.\n",
    "        depth: Embedding depth.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: Embedding tensor of shape (batch, seq, depth).\n",
    "    \"\"\"\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    pos_enc = wpe(seq_len, depth)\n",
    "    x = wte(x, vocab_size, depth)\n",
    "    return x + pos_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba89373-d670-440d-ad53-347440e7346a",
   "metadata": {},
   "source": [
    "### Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5585f2aa-1f3b-4769-aabe-07cac5015b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def msa(x: tf.Tensor, n_head: int, d_mha: int, drop_rate: float) -> tf.Tensor:\n",
    "    \"\"\"Multi-head Self Attention.\n",
    "\n",
    "    Args:\n",
    "        x: input tensor of shape (batch_size, len_q, d_model)\n",
    "        n_head: number of heads\n",
    "        d_mha: dimension of multi-head attention\n",
    "        drop_rate: dropout rate\n",
    "\n",
    "    Returns:\n",
    "        output tensor of shape (batch_size, len_q, d_model)\n",
    "    \"\"\"\n",
    "    x_org = tf.identity(x)\n",
    "    x = tf.keras.layers.LayerNormalization()(x)\n",
    "    x = tf.keras.layers.MultiHeadAttention(\n",
    "        num_heads=n_head,\n",
    "        key_dim=d_mha,\n",
    "        dropout=drop_rate,\n",
    "    )(query=x, key=x, value=x, return_attention_scores=False)\n",
    "    return x + x_org\n",
    "\n",
    "def ff(x: tf.Tensor, d_ff: int, d_model: int, drop_rate: float) -> tf.Tensor:\n",
    "    \"\"\"Feed Forward.\n",
    "\n",
    "    Args:\n",
    "        x: input tensor of shape (batch_size, len_q, d_model)\n",
    "        d_ff: dimension of feed forward\n",
    "        d_model: embedding size\n",
    "        drop_rate: dropout rate\n",
    "\n",
    "    Returns:\n",
    "        output tensor of shape (batch_size, len_q, d_model)\n",
    "    \"\"\"\n",
    "    x_org = tf.identity(x)\n",
    "    x = tf.keras.layers.LayerNormalization()(x)\n",
    "    x = tf.keras.layers.Dense(units=d_ff, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dense(units=d_model)(x)\n",
    "    x = tf.keras.layers.Dropout(rate=drop_rate)(x)\n",
    "    return x + x_org"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0e7432-964a-407a-b818-99e8fbd0632f",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f6a74a7-507c-4829-88ec-bd3490ea57b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(  # noqa: PLR0913\n",
    "    x: tf.Tensor,\n",
    "    n_head: int,\n",
    "    d_mha: int,\n",
    "    d_ff: int,\n",
    "    d_model: int,\n",
    "    drop_rate: float,\n",
    ") -> tf.Tensor:\n",
    "    \"\"\"Encoder of Transformer.\n",
    "\n",
    "    Args:\n",
    "        x: Input tensor.\n",
    "        n_head: Number of heads.\n",
    "        d_mha: Dimension of multi-head attention.\n",
    "        d_ff: Dimension of feed-forward layer.\n",
    "        d_model: Dimension of embedding.\n",
    "        drop_rate: Dropout rate.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: Output tensor.\n",
    "    \"\"\"\n",
    "    x = ff(x, d_ff, d_model, drop_rate)\n",
    "    return msa(x, n_head, d_mha, drop_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e111b109-2076-4415-9901-10760b39d38d",
   "metadata": {},
   "source": [
    "### TX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e93a9c9-8fbf-4894-abcc-8fd333890227",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tx_func(  # noqa: PLR0913\n",
    "    x: tf.Tensor,\n",
    "    vocab_size: int,\n",
    "    n_layer: int,\n",
    "    n_head: int,\n",
    "    d_model: int,\n",
    "    d_mha: int,\n",
    "    d_ff: int,\n",
    "    d_label: int,\n",
    "    drop_rate: float,\n",
    ") -> tf.Tensor:\n",
    "    \"\"\"Transformer Model.\n",
    "\n",
    "    Args:\n",
    "        x: Input tensor (English / translated text) of shape (B, LEN_X).\n",
    "        vocab_size: Vocabulary size.\n",
    "        n_layer: Number of layers.\n",
    "        n_head: Number of heads in multi-head attention.\n",
    "        d_model: Model dimension.\n",
    "        d_mha: Multi-head attention dimension.\n",
    "        d_ff: Feed-forward dimension.\n",
    "        d_label: Label dimension (vocab_size) for output layer.\n",
    "        drop_rate: Dropout rate.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: translated (EN) text of shape (B, LEN_X, d_label).\n",
    "    \"\"\"\n",
    "    x = embedding(x, vocab_size, d_model)\n",
    "    x = tf.keras.layers.Dropout(drop_rate)(x)\n",
    "\n",
    "    for _ in range(n_layer):\n",
    "        x = encoder(x, n_head, d_mha, d_ff, d_model, drop_rate)\n",
    "\n",
    "    return tf.keras.layers.Dense(d_label, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5964c86-a8e5-4814-816e-b58077146b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH = 4\n",
    "VOCAB = 32000\n",
    "N_LAYER = 6\n",
    "N_HEAD = 8\n",
    "D_MODEL = 512\n",
    "D_MHA = D_MODEL // N_HEAD\n",
    "D_FF = D_MODEL * 4\n",
    "D_LABEL = 30522\n",
    "DROP_RATE = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f255b6a1-7093-47cf-a75b-ad8282d3faf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tx_encoder() -> tf.keras.Model:\n",
    "    \"\"\"Get standard Encoder TX transformer model.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: the transformer model\n",
    "    \"\"\"\n",
    "    inputs = tf.keras.Input(shape=(None, ), dtype=tf.int32, name=\"x\")\n",
    "    out = tx_func(\n",
    "        inputs,\n",
    "        VOCAB,\n",
    "        N_LAYER,\n",
    "        N_HEAD,\n",
    "        D_MODEL,\n",
    "        D_MHA,\n",
    "        D_FF,\n",
    "        D_LABEL,\n",
    "        DROP_RATE,\n",
    "    )\n",
    "    return tf.keras.Model(inputs=inputs, outputs=out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f260610-3089-486f-b8dd-ca5b96179f3a",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0fdaa87-2041-467a-b558-11132892e8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-21 00:29:39.815242: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 10, 30522)\n"
     ]
    }
   ],
   "source": [
    "x = tf.random.uniform(\n",
    "    shape=(BATCH, 10),\n",
    "    minval=0,\n",
    "    maxval=VOCAB,\n",
    "    dtype=tf.int32,\n",
    ")\n",
    "\n",
    "tx = get_tx_encoder()\n",
    "prd = tx(x, training=False)\n",
    "print(prd.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2488d162-5237-453c-95ed-d0d1fd795234",
   "metadata": {},
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2815eda8-8ea4-4b50-a1c7-d38489f5b1f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " x (InputLayer)              [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape (TFOpLa  (2,)                         0         ['x[0][0]']                   \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (  ()                           0         ['tf.compat.v1.shape[0][0]']  \n",
      " SlicingOpLambda)                                                                                 \n",
      "                                                                                                  \n",
      " tf.range (TFOpLambda)       (None,)                      0         ['tf.__operators__.getitem[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  (None, 1)                    0         ['tf.range[0][0]']            \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLamb  (None, 256)                  0         ['tf.__operators__.getitem_1[0\n",
      " da)                                                                ][0]']                        \n",
      "                                                                                                  \n",
      " tf.math.sin (TFOpLambda)    (None, 256)                  0         ['tf.math.multiply[0][0]']    \n",
      "                                                                                                  \n",
      " tf.math.cos (TFOpLambda)    (None, 256)                  0         ['tf.math.multiply[0][0]']    \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, None, 512)            1638400   ['x[0][0]']                   \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " tf.concat (TFOpLambda)      (None, 512)                  0         ['tf.math.sin[0][0]',         \n",
      "                                                                     'tf.math.cos[0][0]']         \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOp  (None, None, 512)            0         ['embedding[0][0]',           \n",
      " Lambda)                                                             'tf.concat[0][0]']           \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, None, 512)            0         ['tf.__operators__.add[0][0]']\n",
      "                                                                                                  \n",
      " layer_normalization (Layer  (None, None, 512)            1024      ['dropout[0][0]']             \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, None, 2048)           1050624   ['layer_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, None, 512)            1049088   ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, None, 512)            0         ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " tf.identity (TFOpLambda)    (None, None, 512)            0         ['dropout[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TF  (None, None, 512)            0         ['dropout_1[0][0]',           \n",
      " OpLambda)                                                           'tf.identity[0][0]']         \n",
      "                                                                                                  \n",
      " layer_normalization_1 (Lay  (None, None, 512)            1024      ['tf.__operators__.add_1[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " multi_head_attention (Mult  (None, None, 512)            1050624   ['layer_normalization_1[0][0]'\n",
      " iHeadAttention)                                                    , 'layer_normalization_1[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'layer_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " tf.identity_1 (TFOpLambda)  (None, None, 512)            0         ['tf.__operators__.add_1[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TF  (None, None, 512)            0         ['multi_head_attention[0][0]',\n",
      " OpLambda)                                                           'tf.identity_1[0][0]']       \n",
      "                                                                                                  \n",
      " layer_normalization_2 (Lay  (None, None, 512)            1024      ['tf.__operators__.add_2[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, None, 2048)           1050624   ['layer_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, None, 512)            1049088   ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, None, 512)            0         ['dense_3[0][0]']             \n",
      "                                                                                                  \n",
      " tf.identity_2 (TFOpLambda)  (None, None, 512)            0         ['tf.__operators__.add_2[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TF  (None, None, 512)            0         ['dropout_2[0][0]',           \n",
      " OpLambda)                                                           'tf.identity_2[0][0]']       \n",
      "                                                                                                  \n",
      " layer_normalization_3 (Lay  (None, None, 512)            1024      ['tf.__operators__.add_3[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (Mu  (None, None, 512)            1050624   ['layer_normalization_3[0][0]'\n",
      " ltiHeadAttention)                                                  , 'layer_normalization_3[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'layer_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " tf.identity_3 (TFOpLambda)  (None, None, 512)            0         ['tf.__operators__.add_3[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TF  (None, None, 512)            0         ['multi_head_attention_1[0][0]\n",
      " OpLambda)                                                          ',                            \n",
      "                                                                     'tf.identity_3[0][0]']       \n",
      "                                                                                                  \n",
      " layer_normalization_4 (Lay  (None, None, 512)            1024      ['tf.__operators__.add_4[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, None, 2048)           1050624   ['layer_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, None, 512)            1049088   ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, None, 512)            0         ['dense_5[0][0]']             \n",
      "                                                                                                  \n",
      " tf.identity_4 (TFOpLambda)  (None, None, 512)            0         ['tf.__operators__.add_4[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TF  (None, None, 512)            0         ['dropout_3[0][0]',           \n",
      " OpLambda)                                                           'tf.identity_4[0][0]']       \n",
      "                                                                                                  \n",
      " layer_normalization_5 (Lay  (None, None, 512)            1024      ['tf.__operators__.add_5[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (Mu  (None, None, 512)            1050624   ['layer_normalization_5[0][0]'\n",
      " ltiHeadAttention)                                                  , 'layer_normalization_5[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'layer_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " tf.identity_5 (TFOpLambda)  (None, None, 512)            0         ['tf.__operators__.add_5[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TF  (None, None, 512)            0         ['multi_head_attention_2[0][0]\n",
      " OpLambda)                                                          ',                            \n",
      "                                                                     'tf.identity_5[0][0]']       \n",
      "                                                                                                  \n",
      " layer_normalization_6 (Lay  (None, None, 512)            1024      ['tf.__operators__.add_6[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, None, 2048)           1050624   ['layer_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, None, 512)            1049088   ['dense_6[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         (None, None, 512)            0         ['dense_7[0][0]']             \n",
      "                                                                                                  \n",
      " tf.identity_6 (TFOpLambda)  (None, None, 512)            0         ['tf.__operators__.add_6[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TF  (None, None, 512)            0         ['dropout_4[0][0]',           \n",
      " OpLambda)                                                           'tf.identity_6[0][0]']       \n",
      "                                                                                                  \n",
      " layer_normalization_7 (Lay  (None, None, 512)            1024      ['tf.__operators__.add_7[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (Mu  (None, None, 512)            1050624   ['layer_normalization_7[0][0]'\n",
      " ltiHeadAttention)                                                  , 'layer_normalization_7[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'layer_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " tf.identity_7 (TFOpLambda)  (None, None, 512)            0         ['tf.__operators__.add_7[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_8 (TF  (None, None, 512)            0         ['multi_head_attention_3[0][0]\n",
      " OpLambda)                                                          ',                            \n",
      "                                                                     'tf.identity_7[0][0]']       \n",
      "                                                                                                  \n",
      " layer_normalization_8 (Lay  (None, None, 512)            1024      ['tf.__operators__.add_8[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, None, 2048)           1050624   ['layer_normalization_8[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (None, None, 512)            1049088   ['dense_8[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)         (None, None, 512)            0         ['dense_9[0][0]']             \n",
      "                                                                                                  \n",
      " tf.identity_8 (TFOpLambda)  (None, None, 512)            0         ['tf.__operators__.add_8[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_9 (TF  (None, None, 512)            0         ['dropout_5[0][0]',           \n",
      " OpLambda)                                                           'tf.identity_8[0][0]']       \n",
      "                                                                                                  \n",
      " layer_normalization_9 (Lay  (None, None, 512)            1024      ['tf.__operators__.add_9[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " multi_head_attention_4 (Mu  (None, None, 512)            1050624   ['layer_normalization_9[0][0]'\n",
      " ltiHeadAttention)                                                  , 'layer_normalization_9[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'layer_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " tf.identity_9 (TFOpLambda)  (None, None, 512)            0         ['tf.__operators__.add_9[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_10 (T  (None, None, 512)            0         ['multi_head_attention_4[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'tf.identity_9[0][0]']       \n",
      "                                                                                                  \n",
      " layer_normalization_10 (La  (None, None, 512)            1024      ['tf.__operators__.add_10[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " dense_10 (Dense)            (None, None, 2048)           1050624   ['layer_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_11 (Dense)            (None, None, 512)            1049088   ['dense_10[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)         (None, None, 512)            0         ['dense_11[0][0]']            \n",
      "                                                                                                  \n",
      " tf.identity_10 (TFOpLambda  (None, None, 512)            0         ['tf.__operators__.add_10[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_11 (T  (None, None, 512)            0         ['dropout_6[0][0]',           \n",
      " FOpLambda)                                                          'tf.identity_10[0][0]']      \n",
      "                                                                                                  \n",
      " layer_normalization_11 (La  (None, None, 512)            1024      ['tf.__operators__.add_11[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " multi_head_attention_5 (Mu  (None, None, 512)            1050624   ['layer_normalization_11[0][0]\n",
      " ltiHeadAttention)                                                  ',                            \n",
      "                                                                     'layer_normalization_11[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'layer_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.identity_11 (TFOpLambda  (None, None, 512)            0         ['tf.__operators__.add_11[0][0\n",
      " )                                                                  ]']                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_12 (T  (None, None, 512)            0         ['multi_head_attention_5[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'tf.identity_11[0][0]']      \n",
      "                                                                                                  \n",
      " dense_12 (Dense)            (None, None, 30522)          1565778   ['tf.__operators__.add_12[0][0\n",
      "                                                          6         ]']                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 50956090 (194.38 MB)\n",
      "Trainable params: 50956090 (194.38 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tx.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24abd518-92b9-42d5-9b22-860897e3cabe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
