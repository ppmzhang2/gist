{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "216b56da-5f07-49e6-a5ca-9e20c8aa5769",
   "metadata": {},
   "source": [
    "# Transformer: Encoder - Decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da4656b-786b-49a2-9ded-27c73c583052",
   "metadata": {},
   "source": [
    "## Functional API Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e752ce9-aff0-41fb-b9e3-dd01e980b40c",
   "metadata": {},
   "source": [
    "### Input Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad44aabb-55b2-4374-8867-0dbc4ad02c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def wpe(length: int, depth: int) -> tf.Tensor:\n",
    "    \"\"\"Word Positional Encoding.\n",
    "\n",
    "    This function is used to encode the position of each token in the sequence,\n",
    "    which is then added to the embedding of each token.\n",
    "\n",
    "    Args:\n",
    "        length: Sequence length.\n",
    "        depth: Embedding depth.\n",
    "\n",
    "    Returns:\n",
    "        Positional encoding tensor of shape (length, depth).\n",
    "    \"\"\"\n",
    "    depth = depth / 2\n",
    "\n",
    "    # (seq, 1)\n",
    "    positions = tf.range(length, dtype=tf.float32)[:, tf.newaxis]\n",
    "    # (1, depth)\n",
    "    depths = tf.range(depth, dtype=tf.float32)[tf.newaxis, :] / depth\n",
    "\n",
    "    angle_rates = 1 / (10000**depths)  # (1, depth)\n",
    "    angle_rads = positions * angle_rates  # (pos, depth)\n",
    "\n",
    "    return tf.concat([tf.sin(angle_rads), tf.cos(angle_rads)], axis=-1)\n",
    "\n",
    "\n",
    "def wte(x: tf.Tensor, vocab_size: int, depth: int) -> tf.Tensor:\n",
    "    \"\"\"Word Token Embedding.\n",
    "\n",
    "    This function is used to encode each token in the sequence into a vector.\n",
    "\n",
    "    Args:\n",
    "        x: Token ID sequence tensor of shape (batch, seq).\n",
    "        vocab_size: Vocabulary size.\n",
    "        depth: Embedding depth.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: Embedding tensor of shape (batch, seq, depth).\n",
    "    \"\"\"\n",
    "    return tf.keras.layers.Embedding(vocab_size, depth)(x)\n",
    "\n",
    "\n",
    "def embedding(x: tf.Tensor, vocab_size: int, depth: int) -> tf.Tensor:\n",
    "    \"\"\"Input Embedding.\n",
    "\n",
    "    This function is used to encode each token in the sequence into a vector,\n",
    "    and then add the positional encoding to each token.\n",
    "\n",
    "    Args:\n",
    "        x: Token ID sequence tensor of shape (batch, seq).\n",
    "        vocab_size: Vocabulary size.\n",
    "        depth: Embedding depth.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: Embedding tensor of shape (batch, seq, depth).\n",
    "    \"\"\"\n",
    "    seq_len = tf.shape(x)[1]\n",
    "    pos_enc = wpe(seq_len, depth)\n",
    "    x = wte(x, vocab_size, depth)\n",
    "    return x + pos_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca20e7a3-74a2-4b7a-90e6-cacb854056fd",
   "metadata": {},
   "source": [
    "### Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff67d542-1d65-4b3b-bced-f9494bc89d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def msa(x: tf.Tensor, n_head: int, d_mha: int, drop_rate: float) -> tf.Tensor:\n",
    "    \"\"\"Multi-head Self Attention.\n",
    "\n",
    "    Args:\n",
    "        x: input tensor of shape (batch_size, len_q, d_model)\n",
    "        n_head: number of heads\n",
    "        d_mha: dimension of multi-head attention\n",
    "        drop_rate: dropout rate\n",
    "\n",
    "    Returns:\n",
    "        output tensor of shape (batch_size, len_q, d_model)\n",
    "    \"\"\"\n",
    "    attn_out = tf.keras.layers.MultiHeadAttention(\n",
    "        num_heads=n_head,\n",
    "        key_dim=d_mha,\n",
    "        dropout=drop_rate,\n",
    "    )(query=x, key=x, value=x, return_attention_scores=False)\n",
    "    return tf.keras.layers.LayerNormalization()(attn_out + x)\n",
    "\n",
    "\n",
    "def mca(\n",
    "    x: tf.Tensor,\n",
    "    ctx: tf.Tensor,\n",
    "    n_head: int,\n",
    "    d_mha: int,\n",
    "    drop_rate: float,\n",
    ") -> tf.Tensor:\n",
    "    \"\"\"Multi-head Cross Attention.\n",
    "\n",
    "    Args:\n",
    "        x: input tensor of shape (batch_size, len_q, d_model)\n",
    "        ctx: context tensor of shape (batch_size, len_ctx, d_model)\n",
    "        n_head: number of heads\n",
    "        d_mha: dimension of multi-head attention\n",
    "        drop_rate: dropout rate\n",
    "\n",
    "    Returns:\n",
    "        output tensor of shape (batch_size, len_q, d_model)\n",
    "    \"\"\"\n",
    "    # TODO: get scores\n",
    "    attn_out, _ = tf.keras.layers.MultiHeadAttention(\n",
    "        num_heads=n_head,\n",
    "        key_dim=d_mha,\n",
    "        dropout=drop_rate,\n",
    "    )(query=x, key=ctx, value=ctx, return_attention_scores=True)\n",
    "    return tf.keras.layers.LayerNormalization()(attn_out + x)\n",
    "\n",
    "\n",
    "def mmsa(x: tf.Tensor, n_head: int, d_mha: int, drop_rate: float) -> tf.Tensor:\n",
    "    \"\"\"Masked Multi-head Self Attention.\n",
    "\n",
    "    Args:\n",
    "        x: input tensor of shape (batch_size, len_q, d_model)\n",
    "        n_head: number of heads\n",
    "        d_mha: dimension of multi-head attention\n",
    "        drop_rate: dropout rate\n",
    "\n",
    "    Returns:\n",
    "        output tensor of shape (batch_size, len_q, d_model)\n",
    "    \"\"\"\n",
    "    attn_out = tf.keras.layers.MultiHeadAttention(\n",
    "        num_heads=n_head,\n",
    "        key_dim=d_mha,\n",
    "        dropout=drop_rate,\n",
    "    )(query=x, key=x, value=x, use_causal_mask=True)\n",
    "    return tf.keras.layers.LayerNormalization()(attn_out + x)\n",
    "\n",
    "\n",
    "def ff(x: tf.Tensor, d_ff: int, d_model: int, drop_rate: float) -> tf.Tensor:\n",
    "    \"\"\"Feed Forward.\n",
    "\n",
    "    Args:\n",
    "        x: input tensor of shape (batch_size, len_q, d_model)\n",
    "        d_ff: dimension of feed forward\n",
    "        d_model: embedding size\n",
    "        drop_rate: dropout rate\n",
    "\n",
    "    Returns:\n",
    "        output tensor of shape (batch_size, len_q, d_model)\n",
    "    \"\"\"\n",
    "    x = tf.keras.layers.Dense(units=d_ff, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dense(units=d_model)(x)\n",
    "    x = tf.keras.layers.Dropout(rate=drop_rate)(x)\n",
    "    return tf.keras.layers.LayerNormalization()(x + x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36546238-8a70-4bc4-a948-67069d5a1129",
   "metadata": {},
   "source": [
    "### EncDe - Encoder / Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2ae2ea8-c3dc-40a5-b2fb-2fbdc35d2d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(  # noqa: PLR0913\n",
    "    x: tf.Tensor,\n",
    "    n_head: int,\n",
    "    d_mha: int,\n",
    "    d_ff: int,\n",
    "    d_model: int,\n",
    "    drop_rate: float,\n",
    ") -> tf.Tensor:\n",
    "    \"\"\"Encoder of Transformer.\n",
    "\n",
    "    Args:\n",
    "        x: Input tensor.\n",
    "        n_head: Number of heads.\n",
    "        d_mha: Dimension of multi-head attention.\n",
    "        d_ff: Dimension of feed-forward layer.\n",
    "        d_model: Dimension of embedding.\n",
    "        drop_rate: Dropout rate.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: Output tensor.\n",
    "    \"\"\"\n",
    "    x = msa(x, n_head, d_mha, drop_rate)\n",
    "    return ff(x, d_ff, d_model, drop_rate)\n",
    "\n",
    "\n",
    "def decoder(  # noqa: PLR0913\n",
    "    x: tf.Tensor,\n",
    "    ctx: tf.Tensor,\n",
    "    n_head: int,\n",
    "    d_mha: int,\n",
    "    d_ff: int,\n",
    "    d_model: int,\n",
    "    drop_rate: float,\n",
    ") -> tf.Tensor:\n",
    "    \"\"\"Decoder of Transformer.\n",
    "\n",
    "    Args:\n",
    "        x: Input tensor.\n",
    "        ctx: Context tensor.\n",
    "        n_head: Number of heads.\n",
    "        d_mha: Dimension of multi-head attention.\n",
    "        d_ff: Dimension of feed-forward layer.\n",
    "        d_model: Dimension of embedding.\n",
    "        drop_rate: Dropout rate.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: Output tensor.\n",
    "    \"\"\"\n",
    "    x = mmsa(x, n_head, d_mha, drop_rate)\n",
    "    x = mca(x, ctx, n_head, d_mha, drop_rate)\n",
    "    return ff(x, d_ff, d_model, drop_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f23308a-cd68-4c64-9507-0fd76d33f46c",
   "metadata": {},
   "source": [
    "### TX Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f25b5f4-54fe-43ef-a607-d99e65d38841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tx_func(  # noqa: PLR0913\n",
    "    x: tf.Tensor,\n",
    "    ctx: tf.Tensor,\n",
    "    vocab_size: int,\n",
    "    n_layer: int,\n",
    "    n_head: int,\n",
    "    d_model: int,\n",
    "    d_mha: int,\n",
    "    d_ff: int,\n",
    "    d_label: int,\n",
    "    drop_rate: float,\n",
    ") -> tf.Tensor:\n",
    "    \"\"\"Transformer Model.\n",
    "\n",
    "    Args:\n",
    "        x: Input tensor (English / translated text) of shape (B, LEN_X).\n",
    "        ctx: Input tensor (Portuguese / original text) of shape (B, LEN_CTX).\n",
    "        vocab_size: Vocabulary size.\n",
    "        n_layer: Number of layers.\n",
    "        n_head: Number of heads in multi-head attention.\n",
    "        d_model: Model dimension.\n",
    "        d_mha: Multi-head attention dimension.\n",
    "        d_ff: Feed-forward dimension.\n",
    "        d_label: Label dimension (vocab_size) for output layer.\n",
    "        drop_rate: Dropout rate.\n",
    "\n",
    "    Returns:\n",
    "        tf.Tensor: translated (EN) text of shape (B, LEN_X, d_label).\n",
    "    \"\"\"\n",
    "    ctx = embedding(ctx, vocab_size, d_model)\n",
    "    ctx = tf.keras.layers.Dropout(drop_rate)(ctx)\n",
    "\n",
    "    for _ in range(n_layer):\n",
    "        ctx = encoder(ctx, n_head, d_mha, d_ff, d_model, drop_rate)\n",
    "\n",
    "    x = embedding(x, vocab_size, d_model)\n",
    "    x = tf.keras.layers.Dropout(drop_rate)(x)\n",
    "\n",
    "    for _ in range(n_layer):\n",
    "        x = decoder(x, ctx, n_head, d_mha, d_ff, d_model, drop_rate)\n",
    "\n",
    "    return tf.keras.layers.Dense(d_label, activation=\"softmax\")(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "700a1ab7-fca5-4ec0-956b-124c1b25f940",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH = 4\n",
    "VOCAB = 32000\n",
    "N_LAYER = 6\n",
    "N_HEAD = 8\n",
    "D_MODEL = 512\n",
    "D_MHA = D_MODEL // N_HEAD\n",
    "D_FF = D_MODEL * 4\n",
    "D_LABEL = 30522\n",
    "DROP_RATE = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "132225ce-6eee-4970-9691-8ca77a6dd0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tx_encde() -> tf.keras.Model:\n",
    "    \"\"\"Get standard EncDe TX transformer model.\n",
    "\n",
    "    Returns:\n",
    "        tf.keras.Model: the transformer model, whose specs stick to the\n",
    "            original paper.\n",
    "    \"\"\"\n",
    "    input_x = tf.keras.Input(shape=(None, ), dtype=tf.int32, name=\"x\")\n",
    "    input_ctx = tf.keras.Input(shape=(None, ), dtype=tf.int32, name=\"ctx\")\n",
    "    out = tx_func(\n",
    "        input_x,\n",
    "        input_ctx,\n",
    "        VOCAB,\n",
    "        N_LAYER,\n",
    "        N_HEAD,\n",
    "        D_MODEL,\n",
    "        D_MHA,\n",
    "        D_FF,\n",
    "        D_LABEL,\n",
    "        DROP_RATE,\n",
    "    )\n",
    "    return tf.keras.Model(inputs=[input_x, input_ctx], outputs=out)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a253ab2d-bf5a-4415-97a2-a4f7f6f7c702",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02a44cb7-9c51-4cfb-aad4-d7e3b59cffbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-21 00:06:09.846981: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 10, 30522)\n"
     ]
    }
   ],
   "source": [
    "x_en = tf.random.uniform(\n",
    "    shape=(BATCH, 10),\n",
    "    minval=0,\n",
    "    maxval=VOCAB,\n",
    "    dtype=tf.int32,\n",
    ")\n",
    "x_pt = tf.random.uniform(\n",
    "    shape=(BATCH, 20),\n",
    "    minval=0,\n",
    "    maxval=VOCAB,\n",
    "    dtype=tf.int32,\n",
    ")\n",
    "\n",
    "tx = get_tx_encde()\n",
    "prd = tx((x_en, x_pt), training=False)\n",
    "print(prd.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe8e13a-37e5-46df-9a10-64dbb3ef01b6",
   "metadata": {},
   "source": [
    "### Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd65a7e4-a9ad-4a16-a488-20b06ff4749e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " ctx (InputLayer)            [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape (TFOpLa  (2,)                         0         ['ctx[0][0]']                 \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (  ()                           0         ['tf.compat.v1.shape[0][0]']  \n",
      " SlicingOpLambda)                                                                                 \n",
      "                                                                                                  \n",
      " tf.range (TFOpLambda)       (None,)                      0         ['tf.__operators__.getitem[0][\n",
      "                                                                    0]']                          \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_1  (None, 1)                    0         ['tf.range[0][0]']            \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLamb  (None, 256)                  0         ['tf.__operators__.getitem_1[0\n",
      " da)                                                                ][0]']                        \n",
      "                                                                                                  \n",
      " tf.math.sin (TFOpLambda)    (None, 256)                  0         ['tf.math.multiply[0][0]']    \n",
      "                                                                                                  \n",
      " tf.math.cos (TFOpLambda)    (None, 256)                  0         ['tf.math.multiply[0][0]']    \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (None, None, 512)            1638400   ['ctx[0][0]']                 \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " tf.concat (TFOpLambda)      (None, 512)                  0         ['tf.math.sin[0][0]',         \n",
      "                                                                     'tf.math.cos[0][0]']         \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOp  (None, None, 512)            0         ['embedding[0][0]',           \n",
      " Lambda)                                                             'tf.concat[0][0]']           \n",
      "                                                                                                  \n",
      " dropout (Dropout)           (None, None, 512)            0         ['tf.__operators__.add[0][0]']\n",
      "                                                                                                  \n",
      " multi_head_attention (Mult  (None, None, 512)            1050624   ['dropout[0][0]',             \n",
      " iHeadAttention)                                                     'dropout[0][0]',             \n",
      "                                                                     'dropout[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TF  (None, None, 512)            0         ['multi_head_attention[0][0]',\n",
      " OpLambda)                                                           'dropout[0][0]']             \n",
      "                                                                                                  \n",
      " layer_normalization (Layer  (None, None, 512)            1024      ['tf.__operators__.add_1[0][0]\n",
      " Normalization)                                                     ']                            \n",
      "                                                                                                  \n",
      " dense (Dense)               (None, None, 2048)           1050624   ['layer_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (None, None, 512)            1049088   ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, None, 512)            0         ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TF  (None, None, 512)            0         ['dropout_1[0][0]',           \n",
      " OpLambda)                                                           'dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " layer_normalization_1 (Lay  (None, None, 512)            1024      ['tf.__operators__.add_2[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " multi_head_attention_1 (Mu  (None, None, 512)            1050624   ['layer_normalization_1[0][0]'\n",
      " ltiHeadAttention)                                                  , 'layer_normalization_1[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'layer_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TF  (None, None, 512)            0         ['multi_head_attention_1[0][0]\n",
      " OpLambda)                                                          ',                            \n",
      "                                                                     'layer_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " layer_normalization_2 (Lay  (None, None, 512)            1024      ['tf.__operators__.add_3[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, None, 2048)           1050624   ['layer_normalization_2[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, None, 512)            1049088   ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)         (None, None, 512)            0         ['dense_3[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TF  (None, None, 512)            0         ['dropout_2[0][0]',           \n",
      " OpLambda)                                                           'dropout_2[0][0]']           \n",
      "                                                                                                  \n",
      " layer_normalization_3 (Lay  (None, None, 512)            1024      ['tf.__operators__.add_4[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " multi_head_attention_2 (Mu  (None, None, 512)            1050624   ['layer_normalization_3[0][0]'\n",
      " ltiHeadAttention)                                                  , 'layer_normalization_3[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'layer_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TF  (None, None, 512)            0         ['multi_head_attention_2[0][0]\n",
      " OpLambda)                                                          ',                            \n",
      "                                                                     'layer_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " layer_normalization_4 (Lay  (None, None, 512)            1024      ['tf.__operators__.add_5[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, None, 2048)           1050624   ['layer_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_5 (Dense)             (None, None, 512)            1049088   ['dense_4[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)         (None, None, 512)            0         ['dense_5[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TF  (None, None, 512)            0         ['dropout_3[0][0]',           \n",
      " OpLambda)                                                           'dropout_3[0][0]']           \n",
      "                                                                                                  \n",
      " layer_normalization_5 (Lay  (None, None, 512)            1024      ['tf.__operators__.add_6[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " multi_head_attention_3 (Mu  (None, None, 512)            1050624   ['layer_normalization_5[0][0]'\n",
      " ltiHeadAttention)                                                  , 'layer_normalization_5[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'layer_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TF  (None, None, 512)            0         ['multi_head_attention_3[0][0]\n",
      " OpLambda)                                                          ',                            \n",
      "                                                                     'layer_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " layer_normalization_6 (Lay  (None, None, 512)            1024      ['tf.__operators__.add_7[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " dense_6 (Dense)             (None, None, 2048)           1050624   ['layer_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_7 (Dense)             (None, None, 512)            1049088   ['dense_6[0][0]']             \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)         (None, None, 512)            0         ['dense_7[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_8 (TF  (None, None, 512)            0         ['dropout_4[0][0]',           \n",
      " OpLambda)                                                           'dropout_4[0][0]']           \n",
      "                                                                                                  \n",
      " layer_normalization_7 (Lay  (None, None, 512)            1024      ['tf.__operators__.add_8[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " multi_head_attention_4 (Mu  (None, None, 512)            1050624   ['layer_normalization_7[0][0]'\n",
      " ltiHeadAttention)                                                  , 'layer_normalization_7[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'layer_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_9 (TF  (None, None, 512)            0         ['multi_head_attention_4[0][0]\n",
      " OpLambda)                                                          ',                            \n",
      "                                                                     'layer_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " layer_normalization_8 (Lay  (None, None, 512)            1024      ['tf.__operators__.add_9[0][0]\n",
      " erNormalization)                                                   ']                            \n",
      "                                                                                                  \n",
      " x (InputLayer)              [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " dense_8 (Dense)             (None, None, 2048)           1050624   ['layer_normalization_8[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape_1 (TFOp  (2,)                         0         ['x[0][0]']                   \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " dense_9 (Dense)             (None, None, 512)            1049088   ['dense_8[0][0]']             \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2  ()                           0         ['tf.compat.v1.shape_1[0][0]']\n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)         (None, None, 512)            0         ['dense_9[0][0]']             \n",
      "                                                                                                  \n",
      " tf.range_1 (TFOpLambda)     (None,)                      0         ['tf.__operators__.getitem_2[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " tf.__operators__.add_10 (T  (None, None, 512)            0         ['dropout_5[0][0]',           \n",
      " FOpLambda)                                                          'dropout_5[0][0]']           \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_3  (None, 1)                    0         ['tf.range_1[0][0]']          \n",
      "  (SlicingOpLambda)                                                                               \n",
      "                                                                                                  \n",
      " layer_normalization_9 (Lay  (None, None, 512)            1024      ['tf.__operators__.add_10[0][0\n",
      " erNormalization)                                                   ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLa  (None, 256)                  0         ['tf.__operators__.getitem_3[0\n",
      " mbda)                                                              ][0]']                        \n",
      "                                                                                                  \n",
      " multi_head_attention_5 (Mu  (None, None, 512)            1050624   ['layer_normalization_9[0][0]'\n",
      " ltiHeadAttention)                                                  , 'layer_normalization_9[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'layer_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " tf.math.sin_1 (TFOpLambda)  (None, 256)                  0         ['tf.math.multiply_1[0][0]']  \n",
      "                                                                                                  \n",
      " tf.math.cos_1 (TFOpLambda)  (None, 256)                  0         ['tf.math.multiply_1[0][0]']  \n",
      "                                                                                                  \n",
      " tf.__operators__.add_11 (T  (None, None, 512)            0         ['multi_head_attention_5[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'layer_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)     (None, None, 512)            1638400   ['x[0][0]']                   \n",
      "                                                          0                                       \n",
      "                                                                                                  \n",
      " tf.concat_1 (TFOpLambda)    (None, 512)                  0         ['tf.math.sin_1[0][0]',       \n",
      "                                                                     'tf.math.cos_1[0][0]']       \n",
      "                                                                                                  \n",
      " layer_normalization_10 (La  (None, None, 512)            1024      ['tf.__operators__.add_11[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_13 (T  (None, None, 512)            0         ['embedding_1[0][0]',         \n",
      " FOpLambda)                                                          'tf.concat_1[0][0]']         \n",
      "                                                                                                  \n",
      " dense_10 (Dense)            (None, None, 2048)           1050624   ['layer_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)         (None, None, 512)            0         ['tf.__operators__.add_13[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " dense_11 (Dense)            (None, None, 512)            1049088   ['dense_10[0][0]']            \n",
      "                                                                                                  \n",
      " multi_head_attention_6 (Mu  (None, None, 512)            1050624   ['dropout_7[0][0]',           \n",
      " ltiHeadAttention)                                                   'dropout_7[0][0]',           \n",
      "                                                                     'dropout_7[0][0]']           \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)         (None, None, 512)            0         ['dense_11[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_14 (T  (None, None, 512)            0         ['multi_head_attention_6[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'dropout_7[0][0]']           \n",
      "                                                                                                  \n",
      " tf.__operators__.add_12 (T  (None, None, 512)            0         ['dropout_6[0][0]',           \n",
      " FOpLambda)                                                          'dropout_6[0][0]']           \n",
      "                                                                                                  \n",
      " layer_normalization_12 (La  (None, None, 512)            1024      ['tf.__operators__.add_14[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " layer_normalization_11 (La  (None, None, 512)            1024      ['tf.__operators__.add_12[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " multi_head_attention_7 (Mu  ((None, None, 512),          1050624   ['layer_normalization_12[0][0]\n",
      " ltiHeadAttention)            (None, 8, None, None))                ',                            \n",
      "                                                                     'layer_normalization_11[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'layer_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_15 (T  (None, None, 512)            0         ['multi_head_attention_7[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'layer_normalization_12[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " layer_normalization_13 (La  (None, None, 512)            1024      ['tf.__operators__.add_15[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " dense_12 (Dense)            (None, None, 2048)           1050624   ['layer_normalization_13[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_13 (Dense)            (None, None, 512)            1049088   ['dense_12[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)         (None, None, 512)            0         ['dense_13[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_16 (T  (None, None, 512)            0         ['dropout_8[0][0]',           \n",
      " FOpLambda)                                                          'dropout_8[0][0]']           \n",
      "                                                                                                  \n",
      " layer_normalization_14 (La  (None, None, 512)            1024      ['tf.__operators__.add_16[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " multi_head_attention_8 (Mu  (None, None, 512)            1050624   ['layer_normalization_14[0][0]\n",
      " ltiHeadAttention)                                                  ',                            \n",
      "                                                                     'layer_normalization_14[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'layer_normalization_14[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_17 (T  (None, None, 512)            0         ['multi_head_attention_8[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'layer_normalization_14[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " layer_normalization_15 (La  (None, None, 512)            1024      ['tf.__operators__.add_17[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " multi_head_attention_9 (Mu  ((None, None, 512),          1050624   ['layer_normalization_15[0][0]\n",
      " ltiHeadAttention)            (None, 8, None, None))                ',                            \n",
      "                                                                     'layer_normalization_11[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'layer_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_18 (T  (None, None, 512)            0         ['multi_head_attention_9[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'layer_normalization_15[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " layer_normalization_16 (La  (None, None, 512)            1024      ['tf.__operators__.add_18[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " dense_14 (Dense)            (None, None, 2048)           1050624   ['layer_normalization_16[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_15 (Dense)            (None, None, 512)            1049088   ['dense_14[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)         (None, None, 512)            0         ['dense_15[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_19 (T  (None, None, 512)            0         ['dropout_9[0][0]',           \n",
      " FOpLambda)                                                          'dropout_9[0][0]']           \n",
      "                                                                                                  \n",
      " layer_normalization_17 (La  (None, None, 512)            1024      ['tf.__operators__.add_19[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " multi_head_attention_10 (M  (None, None, 512)            1050624   ['layer_normalization_17[0][0]\n",
      " ultiHeadAttention)                                                 ',                            \n",
      "                                                                     'layer_normalization_17[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'layer_normalization_17[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_20 (T  (None, None, 512)            0         ['multi_head_attention_10[0][0\n",
      " FOpLambda)                                                         ]',                           \n",
      "                                                                     'layer_normalization_17[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " layer_normalization_18 (La  (None, None, 512)            1024      ['tf.__operators__.add_20[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " multi_head_attention_11 (M  ((None, None, 512),          1050624   ['layer_normalization_18[0][0]\n",
      " ultiHeadAttention)           (None, 8, None, None))                ',                            \n",
      "                                                                     'layer_normalization_11[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'layer_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_21 (T  (None, None, 512)            0         ['multi_head_attention_11[0][0\n",
      " FOpLambda)                                                         ]',                           \n",
      "                                                                     'layer_normalization_18[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " layer_normalization_19 (La  (None, None, 512)            1024      ['tf.__operators__.add_21[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " dense_16 (Dense)            (None, None, 2048)           1050624   ['layer_normalization_19[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_17 (Dense)            (None, None, 512)            1049088   ['dense_16[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)        (None, None, 512)            0         ['dense_17[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_22 (T  (None, None, 512)            0         ['dropout_10[0][0]',          \n",
      " FOpLambda)                                                          'dropout_10[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_20 (La  (None, None, 512)            1024      ['tf.__operators__.add_22[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " multi_head_attention_12 (M  (None, None, 512)            1050624   ['layer_normalization_20[0][0]\n",
      " ultiHeadAttention)                                                 ',                            \n",
      "                                                                     'layer_normalization_20[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'layer_normalization_20[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_23 (T  (None, None, 512)            0         ['multi_head_attention_12[0][0\n",
      " FOpLambda)                                                         ]',                           \n",
      "                                                                     'layer_normalization_20[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " layer_normalization_21 (La  (None, None, 512)            1024      ['tf.__operators__.add_23[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " multi_head_attention_13 (M  ((None, None, 512),          1050624   ['layer_normalization_21[0][0]\n",
      " ultiHeadAttention)           (None, 8, None, None))                ',                            \n",
      "                                                                     'layer_normalization_11[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'layer_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_24 (T  (None, None, 512)            0         ['multi_head_attention_13[0][0\n",
      " FOpLambda)                                                         ]',                           \n",
      "                                                                     'layer_normalization_21[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " layer_normalization_22 (La  (None, None, 512)            1024      ['tf.__operators__.add_24[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " dense_18 (Dense)            (None, None, 2048)           1050624   ['layer_normalization_22[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_19 (Dense)            (None, None, 512)            1049088   ['dense_18[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)        (None, None, 512)            0         ['dense_19[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_25 (T  (None, None, 512)            0         ['dropout_11[0][0]',          \n",
      " FOpLambda)                                                          'dropout_11[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_23 (La  (None, None, 512)            1024      ['tf.__operators__.add_25[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " multi_head_attention_14 (M  (None, None, 512)            1050624   ['layer_normalization_23[0][0]\n",
      " ultiHeadAttention)                                                 ',                            \n",
      "                                                                     'layer_normalization_23[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'layer_normalization_23[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_26 (T  (None, None, 512)            0         ['multi_head_attention_14[0][0\n",
      " FOpLambda)                                                         ]',                           \n",
      "                                                                     'layer_normalization_23[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " layer_normalization_24 (La  (None, None, 512)            1024      ['tf.__operators__.add_26[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " multi_head_attention_15 (M  ((None, None, 512),          1050624   ['layer_normalization_24[0][0]\n",
      " ultiHeadAttention)           (None, 8, None, None))                ',                            \n",
      "                                                                     'layer_normalization_11[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'layer_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_27 (T  (None, None, 512)            0         ['multi_head_attention_15[0][0\n",
      " FOpLambda)                                                         ]',                           \n",
      "                                                                     'layer_normalization_24[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " layer_normalization_25 (La  (None, None, 512)            1024      ['tf.__operators__.add_27[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " dense_20 (Dense)            (None, None, 2048)           1050624   ['layer_normalization_25[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_21 (Dense)            (None, None, 512)            1049088   ['dense_20[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)        (None, None, 512)            0         ['dense_21[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_28 (T  (None, None, 512)            0         ['dropout_12[0][0]',          \n",
      " FOpLambda)                                                          'dropout_12[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_26 (La  (None, None, 512)            1024      ['tf.__operators__.add_28[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " multi_head_attention_16 (M  (None, None, 512)            1050624   ['layer_normalization_26[0][0]\n",
      " ultiHeadAttention)                                                 ',                            \n",
      "                                                                     'layer_normalization_26[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'layer_normalization_26[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_29 (T  (None, None, 512)            0         ['multi_head_attention_16[0][0\n",
      " FOpLambda)                                                         ]',                           \n",
      "                                                                     'layer_normalization_26[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " layer_normalization_27 (La  (None, None, 512)            1024      ['tf.__operators__.add_29[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " multi_head_attention_17 (M  ((None, None, 512),          1050624   ['layer_normalization_27[0][0]\n",
      " ultiHeadAttention)           (None, 8, None, None))                ',                            \n",
      "                                                                     'layer_normalization_11[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'layer_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_30 (T  (None, None, 512)            0         ['multi_head_attention_17[0][0\n",
      " FOpLambda)                                                         ]',                           \n",
      "                                                                     'layer_normalization_27[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " layer_normalization_28 (La  (None, None, 512)            1024      ['tf.__operators__.add_30[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " dense_22 (Dense)            (None, None, 2048)           1050624   ['layer_normalization_28[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " dense_23 (Dense)            (None, None, 512)            1049088   ['dense_22[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)        (None, None, 512)            0         ['dense_23[0][0]']            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_31 (T  (None, None, 512)            0         ['dropout_13[0][0]',          \n",
      " FOpLambda)                                                          'dropout_13[0][0]']          \n",
      "                                                                                                  \n",
      " layer_normalization_29 (La  (None, None, 512)            1024      ['tf.__operators__.add_31[0][0\n",
      " yerNormalization)                                                  ]']                           \n",
      "                                                                                                  \n",
      " dense_24 (Dense)            (None, None, 30522)          1565778   ['layer_normalization_29[0][0]\n",
      "                                                          6         ']                            \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 92564282 (353.10 MB)\n",
      "Trainable params: 92564282 (353.10 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tx.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
